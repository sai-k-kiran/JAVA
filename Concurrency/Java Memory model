-XmsSetting — initial Heap size

-XmxSetting — maximum Heap size

-XX:NewSizeSetting — new generation heap size

-XX:MaxNewSizeSetting — maximum New generation heap size

-XX:MaxPermGenSetting — maximum size of Permanent generation

-XX:SurvivorRatioSetting — new heap size ratios (e.g. if Young Gen size is 10m and memory switch is –XX:SurvivorRatio=2, then 5m will be reserved for Eden space 
    and 2.5m each for both Survivor spaces, default value = 8)

-XX:NewRatio — providing ratio of Old/New Gen sizes (default value = 2)

1) Heap Memory

    - Heap is divided into 2 parts — Young Generation and Old Generation
    - Heap is allocated when JVM starts up (Initial size: -Xms)
    - Heap size increases/decreases while the application is running
    - Maximum size: -Xmx

1.1) Young Generation

    - This is reserved for containing newly-allocated objects
    - Young Gen includes three parts — Eden Memory and two Survivor Memory spaces (S0, S1)
    - Most of the newly-created objects goes Eden space.
    - When Eden space is filled with objects, Minor GC (a.k.a. Young Collection) is performed and all the survivor objects are moved to one of the survivor spaces.
    - Minor GC also checks the survivor objects and move them to the other survivor space. So at a time, one of the survivor space is always empty.
    - Objects that are survived after many cycles of GC, are moved to the Old generation memory space. Usually its done by setting a threshold for the age of the young 
        generation objects before they become eligible to promote to Old generation.

1.2) Old Generation

    - This is reserved for containing long lived objects that could survive after many rounds of Minor GC
    - When Old Gen space is full, Major GC (a.k.a. Old Collection) is performed (usually takes longer time)

2) Non-Heap Memory

    - This includes Permanent Generation (Replaced by Metaspace since Java 8)
    - Perm Gen stores per-class structures such as runtime constant pool, field and method data, and the code for methods and constructors, as well as interned Strings
    - Its size can be changed using -XX:PermSize and -XX:MaxPermSize

3) Cache Memory

    - This includes Code Cache
    - Stores compiled code (i.e. native code) generated by JIT compiler, JVM internal structures, loaded profiler agent code and data, etc.
    - When Code Cache exceeds a threshold, it gets flushed (and objects are not relocated by the GC).

Stack vs. Heap
Java Stack memory is used for execution of a thread and it contains method specific values and references to other objects in Heap

-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

cs.umd web page

At the processor level, memory model defines necessary & sufficient conditions for knowing that write by one processor is visible to all processors & vice versa.
Some processors exhibit strong memory models than others. Other processors define weaker memory model where special instructions called "memory barriers" are required
to flush or invalidate the local processor cache in order to see writes by otehr processors. These memory barriers are usually performed when lock and unlock actions 
are taken. The JMM works with the processor architecture memory model and guarantees memory variable visibility.

It can sometimes be easier to write programs for strong memory models, because of the reduced(but still needed) need for memory barriers. Recent trends in processor 
design have encouraged weaker memory models, because the relaxations they make for cache consistency allow for greater scalability across multiple processors and 
larger amounts of memory.

The issue of when a write becomes visible to another thread is compounded by the compiler's reordering of code. For example, the compiler might decide that it is more 
efficient to move a write operation later in the program; as long as this code motion does not change the program's semantics, it is free to do so.  If a compiler 
defers an operation, another thread will not see it until it is performed; this mirrors the effect of caching.

Writes to memory can be moved earlier in the program, other threads might see the write before it actually(supposed to) happened.

Class Reordering {
  int x = 0, y = 0;
  public void writer() {
    x = 1;
    y = 2;
  }

  public void reader() {
    int r1 = y;
    int r2 = x;
  }
}

Let execute 2 threads concurrently. y is set to 2. Because "y = 2" line came after "x = 1", we can think that x is set to 1. However the writes may have been
re-ordered. The write to y happens first > reader() is called > write to x happens last. In that case, x is read to be 0.

The Java Memory Model describes what behaviors are legal in multithreaded code, and how threads may interact through memory. It describes the relationship between 
variables in a program and the low-level details of storing and retrieving them to and from memory or registers in a real computer system. It does this in a way 
that can be implemented correctly using a wide variety of hardware and a wide variety of compiler optimizations.

What is meant by reordering?

There are no. of cases where the instructions may appear to execute in different order than specified the program. The compiler is free to re-order the instructions
in the name of optimization. Data may be moved between registers, processor caches, and main memory in different order than specified by the program.

For example, if a thread writes to field a and then to field b, and the value of b does not depend on the value of a, then the compiler is free to reorder these 
operations, and the cache is free to flush b to main memory before a. There are a no. of potential sources of reordering, such as the compiler,  JIT, & the cache.
Events that fall into this category are delayed operations, out-of-order operations, and race conditions.

Reordering occurs at the different memory model levels and is the cause of unexpected program behavior. Compilers and runtime engines can also exercise a reordering 
to optimize program code. These actions could force the JMM not to honor its visibility guarantees. To overcome all these drawbacks, we need synchronization.

When we talk about incorrectly synchronized code in the context of the Java Memory Model, we mean any code where

    - there is a write of a variable by one thread,
    - there is a read of the same variable by another thread and
    - the write and read are not ordered by synchronization

When these rules are violated, we say we have a data race on that variable. A program with a data race is an incorrectly synchronized program.

-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

What does synchronization do?
synchronization is thought of as "mutual exclusion" where a monitor held by one thread at a time, no other thread can access the shared resource until the monitor
is released by the thread & exits the synchronized blocked.

But there is more to synchronization. Synchronization ensures that write by one thread is visible to other threads in a predictable manner which synchronize on
the same monitor. After we exit a synchronized block, we release the monitor, which has the effect of flushing the cache to main memory, so that writes made by 
this thread can be visible to other threads.  

Before we can enter a synchronized block, we acquire the monitor, which has the effect of invalidating the local processor cache so that variables will be 
reloaded from main memory. We will then be able to see all of the writes made visible by the previous release. 

Synchronization prevents reordering operations that impede JMM visibility guarantees. The term action is used to describe what the JMM does within threads. JMM 
actions include variable read and write, monitor locks and unlock, as well as thread start and join operations. Since we are working with a procedural language, 
our code instructions must be run in order. To uphold its guarantee, partial ordering is defined within the JMM. This partial ordering is called happens-before.

The rules of this ordering are as follows:

    - Each action in a thread happens before every action in that thread that comes later in the programs order.
    - An unlock on a monitor happens before every subsequent lock on that same monitor.
    - A write to a volatile field happens before every subsequent read of that same volatile.
    - A call to start() on a thread happens before any actions in the started thread.
    - All actions in a thread happen before any other thread successfully returns from a join() on that thread.

This means that all the memory operations visible to a thread before exiting a synchronized block is visible to any other thread that acquires the monitor, since
the memory operations happen before the release & the release happens after the acquire.


What does volatile do? 
Volatile fields are special fields which are used for communicating state between threads. Each read of a volatile will see the last write to that volatile by any thread

volatile guarantees coherent access to a field by multiple threads with visibility as its only guarantee. A shared variable declared volatile can only be used with an 
assignment operation. This makes this mechanism a weaker synchronization tool due to it not using any locks. Access to a volatile variable is guaranteed to be performed 
by the program order. 

The compiler and runtime are prohibited from allocating them in registers. They must also ensure that after they are written, they are flushed out of the cache to main 
memory, so they can immediately become visible to other threads. Similarly, before a volatile field is read, the cache must be invalidated so that the value in main 
memory, not the local processor cache, is the one seen. There are also additional restrictions on reordering accesses to volatile variables. 
For the same reasons, the non-volatile variables accompanying a volatile var in a class are also read directly from main memory.

class VolatileExample {
  int x = 0;
  volatile boolean v = false;

  public void writer() {
    x = 42;
    v = true;
  }

  public void reader() {
    if (v == true) {
        print(x);
    }
  }
}

Assume that one thread is calling writer, and another is calling reader. The write to "v" in writer() flushes the write to "x" to memory, and the read of "v" acquires 
that value from memory. Thus, if the reader sees "v = true", it is also guaranteed to see the write to 42 that happened before it. This would not have been true 
under the old memory model.  If "v" were not volatile, then the compiler could reorder the writes in writer, and readers read of x might see 0.

-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

"double-checked locking" problem  

private static Something instance = null;      // make it volatile to fix the problem

public Something getInstance() {
  if (instance == null) {
    synchronized (this) {
      if (instance == null)
        instance = new Something();
    }
  }
  return instance;
}

The writes which initialize instance and the write to the instance field can be reordered by the compiler or the cache, which would have the effect of returning what 
appears to be a partially constructed "Something".

Making the instance field volatile will "fix" the problems with double-checked locking, because then there will be a happens-before relationship between the 
initialization of the Something by the constructing thread and the return of its value by the thread that reads it.

Instead, use the "Initialization On Demand Holder idiom" which is based on static lazy initialization, which is thread-safe and a lot easier to understand.
This is also called "Bill Pugh Singleton Implementation". This is the best implementation for creating a singleton class. You can serialize this class by implementing
Serializable inteface(marker)

public class Singleton{
    private Singleton(){
    }
    public static Singleton getInstance(){
        return IntiailizationOnDemandClassholder.instance;
    }

    private static class IntiailizationOnDemandClassHolder{
        private static final Singleton instance = new Singleton();
    }
}

This code is guaranteed to be correct because of the initialization guarantees for static fields; if a field is set in a static initializer, it is guaranteed to be 
made visible, correctly, to any thread that accesses that class. 

public class ThreadSafeLazySingleton{           // OR use this
    private static ThreadSafeLazySingleton instance;

    public static ThreadSafeLazySingleton getInstance(){
      synchronized(ThreadSafeLazySingleton.class){
          if(instance == null)
              instance = new ThreadSafeLazySingleton();

          return instance;
      } 
    }
}

-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

LAZY INITIALIZATION:

Lazy initialization is the pattern of putting off the creation of an object or process until it is needed. The idea behind this pattern is that you may never need the 
object and thus you will have saved the initialization costs. The main reason that lazy initialization is used is as an optimization. The other use that lazy 
initialization has is breaking tricky circular dependencies in your code.

    public class LazyInitializedSingleton {

        private static LazyInitializedSingleton instance;

        private LazyInitializedSingleton(){}

        public static LazyInitializedSingleton getInstance() {
            if (instance == null) 
                instance = new LazyInitializedSingleton();
            
            return instance;
        }
    }

This implementation works fine in the case of the single-threaded environment, but when it comes to multi-threaded systems, it can cause issues if multiple threads are 
inside the if condition at the same time. It will destroy the singleton pattern and both threads will get different instances of the singleton class

public class ThreadSafeSingleton {           // This is the thread-safe implementation of above code

    private static ThreadSafeSingleton instance;

    private ThreadSafeSingleton(){}

    public static synchronized ThreadSafeSingleton getInstance() {
        if (instance == null) {
            instance = new ThreadSafeSingleton();
        }
        return instance;
    }
}

public class EagerInitializedSingleton {     // Eager initialized singleton class

    private static final EagerInitializedSingleton instance = new EagerInitializedSingleton();

    private EagerInitializedSingleton(){}  // private constructor to avoid client applications using the constructor

    public static EagerInitializedSingleton getInstance() {
        return instance;
    }
}

The above code can be broken using Reflection. The constructor of the above class can be accessed using reflection and a nee Singleton instance can be created.

    public class ReflectionSingletonTest {

        public static void main(String[] args) {
            EagerInitializedSingleton instanceOne = EagerInitializedSingleton.getInstance();
            EagerInitializedSingleton instanceTwo = null;
            try {
                Constructor[] constructors = EagerInitializedSingleton.class.getDeclaredConstructors();
                for (Constructor constructor : constructors) {
                    constructor.setAccessible(true);        // This code will destroy the singleton pattern
                    instanceTwo = (EagerInitializedSingleton) constructor.newInstance();
                    break;
                }
            } catch (Exception e) {
                e.printStackTrace();
            }
            System.out.println(instanceOne.hashCode() + " " + instanceOne.hashCode());  // both hashCode are different, means a different singleton instance
        }
    }

ENUM SINGLETON:
Java ensures that any enum value is instantiated only once in a Java program. Since Java Enum values are globally accessible, so is the singleton. The drawback is that 
the enum type is somewhat inflexible (for example, it does not allow lazy initialization).

    public enum EnumSingleton {

        INSTANCE;

        public static void doSomething() {
            // do something
        }
    }

